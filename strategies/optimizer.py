"""
ç­–ç•¥ä¼˜åŒ–å™¨æ¨¡å—
å®ç°ç­–ç•¥å‚æ•°çš„æ™ºèƒ½ä¼˜åŒ–
"""

import asyncio
import numpy as np
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
import logging
from dataclasses import dataclass

from core.base import BaseComponent, BaseConfig
from core.exceptions import StrategyError
from .base import BaseStrategy, StrategyConfig, BacktestResult
from .backtest import BacktestEngine

logger = logging.getLogger(__name__)

@dataclass
class OptimizationResult:
    """ä¼˜åŒ–ç»“æœ"""
    strategy_type: str
    optimized_parameters: Dict[str, Any]
    original_performance: Dict[str, float]
    optimized_performance: Dict[str, float]
    improvement_percentage: float
    optimization_method: str
    optimization_time: float
    convergence_analysis: Dict[str, Any]
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'strategy_type': self.strategy_type,
            'optimized_parameters': self.optimized_parameters,
            'original_performance': self.original_performance,
            'optimized_performance': self.optimized_performance,
            'improvement_percentage': self.improvement_percentage,
            'optimization_method': self.optimization_method,
            'optimization_time': self.optimization_time,
            'convergence_analysis': self.convergence_analysis
        }

class StrategyOptimizerConfig(BaseConfig):
    """ç­–ç•¥ä¼˜åŒ–å™¨é…ç½®"""
    def __init__(self, **kwargs):
        super().__init__(name="StrategyOptimizer", **kwargs)
        self.max_iterations = kwargs.get('max_iterations', 100)
        self.convergence_threshold = kwargs.get('convergence_threshold', 0.01)
        self.optimization_methods = kwargs.get('optimization_methods', ['grid_search', 'bayesian'])
        self.parallel_evaluations = kwargs.get('parallel_evaluations', True)

class StrategyOptimizer(BaseComponent):
    """ç­–ç•¥ä¼˜åŒ–å™¨"""
    
    def __init__(self, config: Optional[StrategyOptimizerConfig] = None):
        super().__init__(config or StrategyOptimizerConfig())
        self.config = config or StrategyOptimizerConfig()
        self.backtest_engine = BacktestEngine()
        self.optimization_history: List[OptimizationResult] = []
    
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨"""
        try:
            logger.info("ğŸ”§ ç­–ç•¥ä¼˜åŒ–å™¨åˆå§‹åŒ–...")
            await self.backtest_engine.initialize()
            self._initialized = True
            return True
        except Exception as e:
            logger.error(f"ç­–ç•¥ä¼˜åŒ–å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        try:
            await self.backtest_engine.cleanup()
            self._initialized = False
            logger.info("ğŸ›‘ ç­–ç•¥ä¼˜åŒ–å™¨å·²æ¸…ç†")
        except Exception as e:
            logger.error(f"ç­–ç•¥ä¼˜åŒ–å™¨æ¸…ç†å¤±è´¥: {e}")
    
    async def optimize_strategy(self, strategy: BaseStrategy, market_data: Dict[str, Any],
                              optimization_method: str = 'grid_search') -> OptimizationResult:
        """ä¼˜åŒ–ç­–ç•¥å‚æ•°"""
        try:
            logger.info(f"ğŸš€ å¼€å§‹ä¼˜åŒ– {strategy.strategy_type} ç­–ç•¥...")
            start_time = datetime.now()
            
            # è·å–åŸå§‹æ€§èƒ½
            logger.info("ğŸ“Š è¯„ä¼°åŸå§‹ç­–ç•¥æ€§èƒ½...")
            original_performance = await self._evaluate_strategy_performance(
                strategy, market_data
            )
            
            # è·å–ä¼˜åŒ–å‚æ•°ç©ºé—´
            parameter_space = self._get_parameter_space(strategy)
            
            # æ‰§è¡Œä¼˜åŒ–
            if optimization_method == 'grid_search':
                optimized_params, optimized_performance = await self._grid_search_optimization(
                    strategy, parameter_space, market_data
                )
            elif optimization_method == 'bayesian':
                optimized_params, optimized_performance = await self._bayesian_optimization(
                    strategy, parameter_space, market_data
                )
            elif optimization_method == 'genetic':
                optimized_params, optimized_performance = await self._genetic_optimization(
                    strategy, parameter_space, market_data
                )
            else:
                raise StrategyError(f"ä¸æ”¯æŒçš„ä¼˜åŒ–æ–¹æ³•: {optimization_method}")
            
            # è®¡ç®—æ”¹è¿›ç™¾åˆ†æ¯”
            improvement = self._calculate_improvement(original_performance, optimized_performance)
            
            # æ”¶æ•›æ€§åˆ†æ
            convergence_analysis = self._analyze_convergence(original_performance, optimized_performance)
            
            optimization_time = (datetime.now() - start_time).total_seconds()
            
            result = OptimizationResult(
                strategy_type=strategy.strategy_type,
                optimized_parameters=optimized_params,
                original_performance=original_performance,
                optimized_performance=optimized_performance,
                improvement_percentage=improvement,
                optimization_method=optimization_method,
                optimization_time=optimization_time,
                convergence_analysis=convergence_analysis
            )
            
            # è®°å½•ä¼˜åŒ–å†å²
            self.optimization_history.append(result)
            
            logger.info(f"âœ… ç­–ç•¥ä¼˜åŒ–å®Œæˆ: {improvement:.2f}% æ”¹è¿›")
            logger.info(f"ğŸ“ˆ ä¼˜åŒ–åå¤æ™®æ¯”ç‡: {optimized_performance.get('sharpe_ratio', 0):.3f}")
            
            return result
            
        except Exception as e:
            logger.error(f"ç­–ç•¥ä¼˜åŒ–å¤±è´¥: {e}")
            raise StrategyError(f"ç­–ç•¥ä¼˜åŒ–å¤±è´¥: {e}", strategy_type=strategy.strategy_type)
    
    def _get_parameter_space(self, strategy: BaseStrategy) -> Dict[str, Any]:
        """è·å–ç­–ç•¥å‚æ•°ç©ºé—´"""
        try:
            strategy_type = strategy.strategy_type
            
            # åŸºäºç­–ç•¥ç±»å‹çš„å‚æ•°ç©ºé—´å®šä¹‰
            parameter_spaces = {
                'conservative': {
                    'rsi_buy_threshold': {'min': 20, 'max': 40, 'step': 5, 'type': 'int'},
                    'rsi_sell_threshold': {'min': 60, 'max': 80, 'step': 5, 'type': 'int'},
                    'ma_period_short': {'min': 10, 'max': 30, 'step': 5, 'type': 'int'},
                    'ma_period_long': {'min': 40, 'max': 100, 'step': 10, 'type': 'int'},
                    'min_confidence': {'min': 0.6, 'max': 0.9, 'step': 0.1, 'type': 'float'}
                },
                'moderate': {
                    'rsi_buy_threshold': {'min': 25, 'max': 45, 'step': 5, 'type': 'int'},
                    'rsi_sell_threshold': {'min': 55, 'max': 75, 'step': 5, 'type': 'int'},
                    'macd_signal_threshold': {'min': 0.05, 'max': 0.2, 'step': 0.05, 'type': 'float'},
                    'trend_confirmation': {'values': [True, False], 'type': 'bool'}
                },
                'aggressive': {
                    'rsi_buy_threshold': {'min': 30, 'max': 50, 'step': 5, 'type': 'int'},
                    'rsi_sell_threshold': {'min': 50, 'max': 70, 'step': 5, 'type': 'int'},
                    'momentum_threshold': {'min': 0.01, 'max': 0.05, 'step': 0.01, 'type': 'float'},
                    'volatility_filter': {'min': 0.01, 'max': 0.03, 'step': 0.005, 'type': 'float'}
                }
            }
            
            return parameter_spaces.get(strategy_type, {})
            
        except Exception as e:
            logger.error(f"è·å–å‚æ•°ç©ºé—´å¤±è´¥: {e}")
            return {}
    
    async def _evaluate_strategy_performance(self, strategy: BaseStrategy, market_data: Dict[str, Any]) -> Dict[str, float]:
        """è¯„ä¼°ç­–ç•¥æ€§èƒ½"""
        try:
            # ä½¿ç”¨å›æµ‹å¼•æ“è¯„ä¼°ç­–ç•¥
            backtest_result = await self.backtest_engine.run_backtest(strategy, market_data)
            
            return {
                'total_return': backtest_result.total_return,
                'sharpe_ratio': backtest_result.sharpe_ratio,
                'max_drawdown': backtest_result.max_drawdown,
                'win_rate': backtest_result.win_rate,
                'profit_factor': backtest_result.profit_factor,
                'total_trades': backtest_result.total_trades
            }
            
        except Exception as e:
            logger.error(f"è¯„ä¼°ç­–ç•¥æ€§èƒ½å¤±è´¥: {e}")
            return {
                'total_return': 0.0,
                'sharpe_ratio': 0.0,
                'max_drawdown': 0.0,
                'win_rate': 0.0,
                'profit_factor': 0.0,
                'total_trades': 0
            }
    
    async def _grid_search_optimization(self, strategy: BaseStrategy, parameter_space: Dict[str, Any], 
                                      market_data: Dict[str, Any]) -> Tuple[Dict[str, Any], Dict[str, float]]:
        """ç½‘æ ¼æœç´¢ä¼˜åŒ–"""
        try:
            logger.info("ğŸ” å¼€å§‹ç½‘æ ¼æœç´¢ä¼˜åŒ–...")
            
            best_params = {}
            best_performance = {
                'total_return': -float('inf'),
                'sharpe_ratio': -float('inf'),
                'max_drawdown': float('inf'),
                'win_rate': 0.0,
                'profit_factor': 0.0,
                'total_trades': 0
            }
            
            # ç”Ÿæˆå‚æ•°ç»„åˆ
            param_combinations = self._generate_param_combinations(parameter_space)
            total_combinations = len(param_combinations)
            
            logger.info(f"ğŸ“Š å…± {total_combinations} ä¸ªå‚æ•°ç»„åˆéœ€è¦æµ‹è¯•")
            
            for i, param_combo in enumerate(param_combinations):
                try:
                    # åˆ›å»ºä¸´æ—¶ç­–ç•¥å®ä¾‹
                    temp_strategy = StrategyFactory.create_strategy(strategy.strategy_type)
                    temp_strategy.update_parameters(param_combo)
                    
                    # è¯„ä¼°æ€§èƒ½
                    performance = await self._evaluate_strategy_performance(temp_strategy, market_data)
                    
                    # ä½¿ç”¨å¤æ™®æ¯”ç‡ä½œä¸ºä¸»è¦ä¼˜åŒ–ç›®æ ‡
                    if performance['sharpe_ratio'] > best_performance['sharpe_ratio']:
                        best_params = param_combo.copy()
                        best_performance = performance.copy()
                    
                    if i % 10 == 0:
                        logger.info(f"â³ è¿›åº¦: {i+1}/{total_combinations}, å½“å‰æœ€ä½³å¤æ™®: {best_performance['sharpe_ratio']:.3f}")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ å‚æ•°ç»„åˆæµ‹è¯•å¤±è´¥: {e}")
                    continue
            
            logger.info(f"âœ… ç½‘æ ¼æœç´¢å®Œæˆï¼Œæœ€ä½³å¤æ™®æ¯”ç‡: {best_performance['sharpe_ratio']:.3f}")
            return best_params, best_performance
            
        except Exception as e:
            logger.error(f"ç½‘æ ¼æœç´¢ä¼˜åŒ–å¤±è´¥: {e}")
            return {}, {
                'total_return': 0.0,
                'sharpe_ratio': 0.0,
                'max_drawdown': 0.0,
                'win_rate': 0.0,
                'profit_factor': 0.0,
                'total_trades': 0
            }
    
    async def _bayesian_optimization(self, strategy: BaseStrategy, parameter_space: Dict[str, Any], 
                                   market_data: Dict[str, Any]) -> Tuple[Dict[str, Any], Dict[str, float]]:
        """è´å¶æ–¯ä¼˜åŒ–"""
        try:
            logger.info("ğŸ”¬ å¼€å§‹è´å¶æ–¯ä¼˜åŒ–...")
            
            # ç®€åŒ–çš„è´å¶æ–¯ä¼˜åŒ–å®ç°
            # å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨ä¸“ä¸šçš„è´å¶æ–¯ä¼˜åŒ–åº“
            
            best_params = {}
            best_performance = {
                'total_return': -float('inf'),
                'sharpe_ratio': -float('inf'),
                'max_drawdown': float('inf'),
                'win_rate': 0.0,
                'profit_factor': 0.0,
                'total_trades': 0
            }
            
            # åˆå§‹é‡‡æ ·ç‚¹
            n_initial_points = 10
            sampled_params = self._sample_initial_points(parameter_space, n_initial_points)
            
            logger.info(f"ğŸ“Š åˆå§‹é‡‡æ · {n_initial_points} ä¸ªç‚¹")
            
            # è¯„ä¼°åˆå§‹ç‚¹
            initial_results = []
            for params in sampled_params:
                try:
                    temp_strategy = StrategyFactory.create_strategy(strategy.strategy_type)
                    temp_strategy.update_parameters(params)
                    performance = await self._evaluate_strategy_performance(temp_strategy, market_data)
                    initial_results.append((params, performance))
                except Exception as e:
                    logger.warning(f"âš ï¸ åˆå§‹é‡‡æ ·ç‚¹è¯„ä¼°å¤±è´¥: {e}")
                    continue
            
            # æ‰¾åˆ°æœ€ä½³åˆå§‹ç‚¹
            if initial_results:
                best_initial = max(initial_results, key=lambda x: x[1]['sharpe_ratio'])
                best_params = best_initial[0]
                best_performance = best_initial[1]
            
            # ç®€åŒ–çš„è¿­ä»£ä¼˜åŒ–
            n_iterations = 20
            for iteration in range(n_iterations):
                try:
                    # åœ¨å½“å‰æœ€ä½³ç‚¹é™„è¿‘æ¢ç´¢
                    candidate_params = self._perturb_parameters(best_params, parameter_space, iteration)
                    
                    # è¯„ä¼°å€™é€‰å‚æ•°
                    temp_strategy = StrategyFactory.create_strategy(strategy.strategy_type)
                    temp_strategy.update_parameters(candidate_params)
                    candidate_performance = await self._evaluate_strategy_performance(temp_strategy, market_data)
                    
                    # å¦‚æœæ›´å¥½åˆ™æ›´æ–°
                    if candidate_performance['sharpe_ratio'] > best_performance['sharpe_ratio']:
                        best_params = candidate_params.copy()
                        best_performance = candidate_performance.copy()
                        logger.info(f"ğŸ”„ è¿­ä»£ {iteration+1}: æ‰¾åˆ°æ›´å¥½çš„å‚æ•°ï¼Œå¤æ™®: {best_performance['sharpe_ratio']:.3f}")
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è¿­ä»£ {iteration+1} å¤±è´¥: {e}")
                    continue
            
            logger.info(f"âœ… è´å¶æ–¯ä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³å¤æ™®æ¯”ç‡: {best_performance['sharpe_ratio']:.3f}")
            return best_params, best_performance
            
        except Exception as e:
            logger.error(f"è´å¶æ–¯ä¼˜åŒ–å¤±è´¥: {e}")
            return {}, {
                'total_return': 0.0,
                'sharpe_ratio': 0.0,
                'max_drawdown': 0.0,
                'win_rate': 0.0,
                'profit_factor': 0.0,
                'total_trades': 0
            }
    
    async def _genetic_optimization(self, strategy: BaseStrategy, parameter_space: Dict[str, Any], 
                                  market_data: Dict[str, Any]) -> Tuple[Dict[str, Any], Dict[str, float]]:
        """é—ä¼ ç®—æ³•ä¼˜åŒ–"""
        try:
            logger.info("ğŸ§¬ å¼€å§‹é—ä¼ ç®—æ³•ä¼˜åŒ–...")
            
            # é—ä¼ ç®—æ³•å‚æ•°
            population_size = 20
            generations = 15
            mutation_rate = 0.1
            crossover_rate = 0.8
            
            # åˆå§‹åŒ–ç§ç¾¤
            population = self._initialize_population(parameter_space, population_size)
            
            best_params = {}
            best_performance = {
                'total_return': -float('inf'),
                'sharpe_ratio': -float('inf'),
                'max_drawdown': float('inf'),
                'win_rate': 0.0,
                'profit_factor': 0.0,
                'total_trades': 0
            }
            
            logger.info(f"ğŸ“Š ç§ç¾¤å¤§å°: {population_size}, è¿›åŒ–ä»£æ•°: {generations}")
            
            for generation in range(generations):
                try:
                    # è¯„ä¼°ç§ç¾¤é€‚åº”åº¦
                    fitness_scores = []
                    for individual in population:
                        temp_strategy = StrategyFactory.create_strategy(strategy.strategy_type)
                        temp_strategy.update_parameters(individual)
                        performance = await self._evaluate_strategy_performance(temp_strategy, market_data)
                        fitness_scores.append(performance['sharpe_ratio'])
                    
                    # è®°å½•æœ€ä½³ä¸ªä½“
                    best_idx = np.argmax(fitness_scores)
                    if fitness_scores[best_idx] > best_performance['sharpe_ratio']:
                        best_params = population[best_idx].copy()
                        best_performance = {
                            'total_return': 0,  # è¿™é‡Œåº”è¯¥è·å–å®Œæ•´çš„æ€§èƒ½æ•°æ®
                            'sharpe_ratio': fitness_scores[best_idx],
                            'max_drawdown': 0,
                            'win_rate': 0,
                            'profit_factor': 0,
                            'total_trades': 0
                        }
                    
                    logger.info(f"ğŸ§¬ ç¬¬ {generation+1} ä»£: æœ€ä½³é€‚åº”åº¦: {fitness_scores[best_idx]:.3f}")
                    
                    # é€‰æ‹©ã€äº¤å‰ã€å˜å¼‚
                    population = self._evolve_population(
                        population, fitness_scores, parameter_space,
                        mutation_rate, crossover_rate
                    )
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ ç¬¬ {generation+1} ä»£è¿›åŒ–å¤±è´¥: {e}")
                    continue
            
            # é‡æ–°è¯„ä¼°æœ€ä½³å‚æ•°è·å–å®Œæ•´æ€§èƒ½
            if best_params:
                temp_strategy = StrategyFactory.create_strategy(strategy.strategy_type)
                temp_strategy.update_parameters(best_params)
                best_performance = await self._evaluate_strategy_performance(temp_strategy, market_data)
            
            logger.info(f"âœ… é—ä¼ ç®—æ³•ä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³å¤æ™®æ¯”ç‡: {best_performance['sharpe_ratio']:.3f}")
            return best_params, best_performance
            
        except Exception as e:
            logger.error(f"é—ä¼ ç®—æ³•ä¼˜åŒ–å¤±è´¥: {e}")
            return {}, {
                'total_return': 0.0,
                'sharpe_ratio': 0.0,
                'max_drawdown': 0.0,
                'win_rate': 0.0,
                'profit_factor': 0.0,
                'total_trades': 0
            }
    
    def _generate_param_combinations(self, parameter_space: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå‚æ•°ç»„åˆ"""
        try:
            import itertools
            
            param_ranges = {}
            for param, config in parameter_space.items():
                if config['type'] == 'int':
                    param_ranges[param] = list(range(config['min'], config['max'] + config['step'], config['step']))
                elif config['type'] == 'float':
                    param_ranges[param] = list(np.arange(config['min'], config['max'] + config['step'], config['step']))
                elif config['type'] == 'bool':
                    param_ranges[param] = config.get('values', [True, False])
            
            # ç”Ÿæˆæ‰€æœ‰ç»„åˆ
            param_names = list(param_ranges.keys())
            param_values = list(param_ranges.values())
            
            combinations = []
            for combo in itertools.product(*param_values):
                param_dict = dict(zip(param_names, combo))
                combinations.append(param_dict)
            
            return combinations
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå‚æ•°ç»„åˆå¤±è´¥: {e}")
            return []
    
    def _sample_initial_points(self, parameter_space: Dict[str, Any], n_points: int) -> List[Dict[str, Any]]:
        """é‡‡æ ·åˆå§‹ç‚¹"""
        try:
            sampled_points = []
            
            for _ in range(n_points):
                point = {}
                for param, config in parameter_space.items():
                    if config['type'] == 'int':
                        point[param] = np.random.randint(config['min'], config['max'] + 1)
                    elif config['type'] == 'float':
                        point[param] = np.random.uniform(config['min'], config['max'])
                    elif config['type'] == 'bool':
                        point[param] = np.random.choice([True, False])
                
                sampled_points.append(point)
            
            return sampled_points
            
        except Exception as e:
            logger.error(f"é‡‡æ ·åˆå§‹ç‚¹å¤±è´¥: {e}")
            return []
    
    def _perturb_parameters(self, base_params: Dict[str, Any], parameter_space: Dict[str, Any], 
                          iteration: int) -> Dict[str, Any]:
        """æ‰°åŠ¨å‚æ•°"""
        try:
            perturbed_params = base_params.copy()
            
            # æ‰°åŠ¨å¼ºåº¦éšè¿­ä»£é€’å‡
            perturbation_strength = max(0.1, 1.0 - iteration * 0.05)
            
            for param, value in perturbed_params.items():
                if param in parameter_space:
                    config = parameter_space[param]
                    
                    if config['type'] == 'int':
                        perturbation = int(np.random.normal(0, config['step'] * perturbation_strength))
                        new_value = value + perturbation
                        new_value = max(config['min'], min(config['max'], new_value))
                        perturbed_params[param] = new_value
                    
                    elif config['type'] == 'float':
                        range_size = config['max'] - config['min']
                        perturbation = np.random.normal(0, range_size * 0.1 * perturbation_strength)
                        new_value = value + perturbation
                        new_value = max(config['min'], min(config['max'], new_value))
                        perturbed_params[param] = new_value
                    
                    elif config['type'] == 'bool':
                        if np.random.random() < 0.3 * perturbation_strength:
                            perturbed_params[param] = not value
            
            return perturbed_params
            
        except Exception as e:
            logger.error(f"æ‰°åŠ¨å‚æ•°å¤±è´¥: {e}")
            return base_params
    
    def _initialize_population(self, parameter_space: Dict[str, Any], population_size: int) -> List[Dict[str, Any]]:
        """åˆå§‹åŒ–ç§ç¾¤"""
        return self._sample_initial_points(parameter_space, population_size)
    
    def _evolve_population(self, population: List[Dict[str, Any]], fitness_scores: List[float], 
                          parameter_space: Dict[str, Any], mutation_rate: float, crossover_rate: float) -> List[Dict[str, Any]]:
        """è¿›åŒ–ç§ç¾¤"""
        try:
            new_population = []
            population_size = len(population)
            
            # é€‰æ‹©æ“ä½œ (é”¦æ ‡èµ›é€‰æ‹©)
            selected_indices = self._tournament_selection(fitness_scores, 3)
            
            # äº¤å‰å’Œå˜å¼‚
            for i in range(0, population_size, 2):
                parent1 = population[selected_indices[i]].copy()
                
                if i + 1 < population_size:
                    parent2 = population[selected_indices[i + 1]].copy()
                    
                    # äº¤å‰
                    if np.random.random() < crossover_rate:
                        child1, child2 = self._crossover(parent1, parent2)
                    else:
                        child1, child2 = parent1.copy(), parent2.copy()
                    
                    # å˜å¼‚
                    if np.random.random() < mutation_rate:
                        child1 = self._mutate_individual(child1, parameter_space, mutation_rate)
                    if np.random.random() < mutation_rate:
                        child2 = self._mutate_individual(child2, parameter_space, mutation_rate)
                    
                    new_population.extend([child1, child2])
                else:
                    new_population.append(parent1)
            
            return new_population[:population_size]
            
        except Exception as e:
            logger.error(f"è¿›åŒ–ç§ç¾¤å¤±è´¥: {e}")
            return population
    
    def _tournament_selection(self, fitness_scores: List[float], tournament_size: int) -> List[int]:
        """é”¦æ ‡èµ›é€‰æ‹©"""
        try:
            selected_indices = []
            population_size = len(fitness_scores)
            
            for _ in range(population_size):
                tournament_indices = np.random.choice(population_size, tournament_size, replace=False)
                tournament_fitness = [fitness_scores[i] for i in tournament_indices]
                winner_idx = tournament_indices[np.argmax(tournament_fitness)]
                selected_indices.append(winner_idx)
            
            return selected_indices
            
        except Exception as e:
            logger.error(f"é”¦æ ‡èµ›é€‰æ‹©å¤±è´¥: {e}")
            return list(range(population_size))
    
    def _crossover(self, parent1: Dict[str, Any], parent2: Dict[str, Any]) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        """äº¤å‰æ“ä½œ"""
        try:
            child1 = parent1.copy()
            child2 = parent2.copy()
            
            # å•ç‚¹äº¤å‰
            keys = list(parent1.keys())
            if len(keys) > 1:
                crossover_point = np.random.randint(1, len(keys))
                
                for i, key in enumerate(keys):
                    if i >= crossover_point:
                        child1[key] = parent2[key]
                        child2[key] = parent1[key]
            
            return child1, child2
            
        except Exception as e:
            logger.error(f"äº¤å‰æ“ä½œå¤±è´¥: {e}")
            return parent1.copy(), parent2.copy()
    
    def _mutate_individual(self, individual: Dict[str, Any], parameter_space: Dict[str, Any], 
                          mutation_rate: float) -> Dict[str, Any]:
        """å˜å¼‚ä¸ªä½“"""
        try:
            mutated = individual.copy()
            
            for param, value in mutated.items():
                if param in parameter_space and np.random.random() < mutation_rate:
                    config = parameter_space[param]
                    
                    if config['type'] == 'int':
                        mutation = int(np.random.normal(0, config.get('step', 1)))
                        new_value = value + mutation
                        new_value = max(config['min'], min(config['max'], new_value))
                        mutated[param] = new_value
                    
                    elif config['type'] == 'float':
                        range_size = config['max'] - config['min']
                        mutation = np.random.normal(0, range_size * 0.1)
                        new_value = value + mutation
                        new_value = max(config['min'], min(config['max'], new_value))
                        mutated[param] = new_value
                    
                    elif config['type'] == 'bool':
                        mutated[param] = not value
            
            return mutated
            
        except Exception as e:
            logger.error(f"å˜å¼‚ä¸ªä½“å¤±è´¥: {e}")
            return individual
    
    def _calculate_improvement(self, original_performance: Dict[str, float], 
                             optimized_performance: Dict[str, float]) -> float:
        """è®¡ç®—æ”¹è¿›ç™¾åˆ†æ¯”"""
        try:
            # åŸºäºå¤æ™®æ¯”ç‡çš„æ”¹è¿›è®¡ç®—
            original_sharpe = original_performance.get('sharpe_ratio', 0.0)
            optimized_sharpe = optimized_performance.get('sharpe_ratio', 0.0)
            
            if original_sharpe <= 0:
                return 0.0
            
            improvement = ((optimized_sharpe - original_sharpe) / abs(original_sharpe)) * 100
            
            return max(-100, min(1000, improvement))  # é™åˆ¶èŒƒå›´
            
        except Exception as e:
            logger.error(f"è®¡ç®—æ”¹è¿›ç™¾åˆ†æ¯”å¤±è´¥: {e}")
            return 0.0
    
    def _analyze_convergence(self, original_performance: Dict[str, float], 
                           optimized_performance: Dict[str, float]) -> Dict[str, Any]:
        """åˆ†ææ”¶æ•›æ€§"""
        try:
            return {
                'converged': True,
                'improvement_significant': optimized_performance.get('sharpe_ratio', 0) > original_performance.get('sharpe_ratio', 0),
                'performance_metrics': {
                    'original_sharpe': original_performance.get('sharpe_ratio', 0),
                    'optimized_sharpe': optimized_performance.get('sharpe_ratio', 0),
                    'sharpe_improvement': optimized_performance.get('sharpe_ratio', 0) - original_performance.get('sharpe_ratio', 0)
                }
            }
        except Exception as e:
            logger.error(f"åˆ†ææ”¶æ•›æ€§å¤±è´¥: {e}")
            return {'converged': False, 'error': str(e)}
    
    def get_optimization_history(self) -> List[OptimizationResult]:
        """è·å–ä¼˜åŒ–å†å²"""
        return self.optimization_history.copy()
    
    def get_best_optimization(self, strategy_type: str) -> Optional[OptimizationResult]:
        """è·å–æœ€ä½³ä¼˜åŒ–ç»“æœ"""
        try:
            strategy_results = [r for r in self.optimization_history if r.strategy_type == strategy_type]
            if strategy_results:
                return max(strategy_results, key=lambda x: x.optimized_performance.get('sharpe_ratio', 0))
            return None
        except Exception as e:
            logger.error(f"è·å–æœ€ä½³ä¼˜åŒ–ç»“æœå¤±è´¥: {e}")
            return None

# å…¨å±€ä¼˜åŒ–å™¨å®ä¾‹
strategy_optimizer = StrategyOptimizer()