"""
Alpha Pilot Bot OKX å·¥å…·æ¨¡å—
åŒ…å«é€šç”¨å·¥å…·å‡½æ•°å’Œè¾…åŠ©åŠŸèƒ½
"""

import os
import time
import json
import threading
import logging
import glob
from typing import Dict, Any, Optional, List
from datetime import datetime, timedelta
from dataclasses import dataclass

def log_info(message):
    """è¾“å‡ºä¿¡æ¯æ—¥å¿—ï¼Œç»Ÿä¸€æ ¼å¼"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print(f"[{timestamp}] [INFO] {message}")

def log_warning(message):
    """è¾“å‡ºè­¦å‘Šæ—¥å¿—ï¼Œç»Ÿä¸€æ ¼å¼"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print(f"[{timestamp}] [WARNING] {message}")

def log_error(message):
    """è¾“å‡ºé”™è¯¯æ—¥å¿—ï¼Œç»Ÿä¸€æ ¼å¼"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print(f"[{timestamp}] [ERROR] {message}")

@dataclass
class CacheItem:
    """ç¼“å­˜é¡¹æ•°æ®ç»“æ„"""
    data: Any
    timestamp: float
    duration: int
    expires_at: float = None
    
    def __post_init__(self):
        if self.expires_at is None:
            self.expires_at = self.timestamp + self.duration

class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, max_size: int = 100):
        self._cache: Dict[str, CacheItem] = {}
        self._max_size = max_size
        self._lock = threading.Lock()
    
    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜æ•°æ®"""
        with self._lock:
            item = self._cache.get(key)
            if item and time.time() - item.timestamp < item.duration:
                return item.data
            elif item:
                # è¿‡æœŸï¼Œåˆ é™¤
                del self._cache[key]
            return None
    
    def set(self, key: str, data: Any, duration: int = 900) -> None:
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        with self._lock:
            if len(self._cache) >= self._max_size:
                # LRUæ¸…ç†
                oldest_key = min(self._cache.keys(), 
                               key=lambda k: self._cache[k].timestamp)
                del self._cache[oldest_key]
            
            self._cache[key] = CacheItem(data, time.time(), duration)
    
    def clear(self, key: str = None) -> None:
        """æ¸…ç†ç¼“å­˜"""
        with self._lock:
            if key:
                self._cache.pop(key, None)
            else:
                self._cache.clear()
    
    def get_stats(self) -> Dict[str, int]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        with self._lock:
            return {
                'size': len(self._cache),
                'max_size': self._max_size
            }
    
    def cleanup_expired(self) -> int:
        """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜é¡¹"""
        current_time = time.time()
        expired_keys = []
        
        with self._lock:
            for key, item in self._cache.items():
                if item.expires_at <= current_time:
                    expired_keys.append(key)
            
            for key in expired_keys:
                del self._cache[key]
        
        return len(expired_keys)

class MemoryManager:
    """å†…å­˜ç®¡ç†å™¨"""
    
    def __init__(self, max_history: int = 100):
        self._histories: Dict[str, List[Any]] = {}
        self._max_history = max_history
        self._lock = threading.Lock()
    
    def add_to_history(self, key: str, item: Any) -> int:
        """å®‰å…¨æ·»åŠ å†å²è®°å½•"""
        with self._lock:
            if key not in self._histories:
                self._histories[key] = []
            
            self._histories[key].append(item)
            
            # é™åˆ¶å†å²é•¿åº¦
            if len(self._histories[key]) > self._max_history:
                self._histories[key].pop(0)
            
            return len(self._histories[key])
    
    def get_history(self, key: str, limit: int = None) -> List[Any]:
        """è·å–å†å²è®°å½•"""
        with self._lock:
            history = self._histories.get(key, [])
            if limit:
                return history[-limit:]
            return history
    
    def clear_history(self, key: str = None) -> bool:
        """æ¸…ç©ºå†å²è®°å½•
        
        æ¸…ç©ºæŒ‡å®šç±»å‹çš„å†å²è®°å½•
        
        Args:
            key: å†å²è®°å½•ç±»å‹é”®
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ¸…ç©º
        """
        with self._lock:
            if key:
                if key in self._histories:
                    self._total_items -= len(self._histories[key])
                    del self._histories[key]
                    return True
                return False
            else:
                self._total_items = 0
                self._histories.clear()
                return True
        with self._lock:
            if key:
                self._histories.pop(key, None)
            else:
                self._histories.clear()
    
    def get_all_keys(self) -> List[str]:
        """è·å–æ‰€æœ‰å†å²è®°å½•é”®
        
        è·å–æ‰€æœ‰å†å²è®°å½•ç±»å‹çš„é”®åˆ—è¡¨
        
        Returns:
            List[str]: å†å²è®°å½•é”®åˆ—è¡¨
        """
        with self._lock:
            return list(self._histories.keys())
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯
        
        è·å–å†…å­˜ç®¡ç†å™¨çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, Any]: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        with self._lock:
            return {
                'total_items': self._total_items,
                'keys_count': len(self._histories),
                'max_per_key': self._max_history,
                'memory_usage': self._total_items * 8  # ç²—ç•¥ä¼°è®¡
            }
    
    def cleanup_old_entries(self, max_age: int = 3600) -> int:
        """æ¸…ç†è¿‡æœŸçš„å†å²è®°å½•
        
        æ¸…ç†è¶…è¿‡æŒ‡å®šæ—¶é—´çš„å†å²è®°å½•é¡¹
        
        Args:
            max_age: æœ€å¤§å­˜æ´»æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            int: æ¸…ç†çš„è®°å½•æ•°é‡
        """
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥æ ¹æ®æ—¶é—´æˆ³æ¸…ç†
        return 0
        with self._lock:
            return {
                'total_items': sum(len(h) for h in self._histories.values()),
                'keys_count': len(self._histories),
                'max_per_key': self._max_history
            }

class SystemMonitor:
    """ç³»ç»Ÿç›‘æ§å™¨"""
    
    def __init__(self):
        self.start_time = time.time()
        self._stats = {
            'trades': 0,
            'errors': 0,
            'warnings': 0,
            'api_calls': 0
        }
        self._lock = threading.Lock()
    
    def increment_counter(self, counter: str, value: int = 1) -> None:
        """å¢åŠ è®¡æ•°å™¨"""
        with self._lock:
            self._stats[counter] = self._stats.get(counter, 0) + value
    
    def get_uptime(self) -> float:
        """è·å–è¿è¡Œæ—¶é—´"""
        return time.time() - self.start_time
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿç»Ÿè®¡"""
        with self._lock:
            return {
                **self._stats,
                'uptime_seconds': self.get_uptime(),
                'uptime_formatted': str(timedelta(seconds=int(self.get_uptime()))),
                'timestamp': datetime.now().isoformat()
            }
    
    def reset_stats(self) -> None:
        """é‡ç½®ç»Ÿè®¡"""
        with self._lock:
            self._stats = {k: 0 for k in self._stats}

class DataValidator:
    """æ•°æ®éªŒè¯å™¨"""
    
    @staticmethod
    def validate_price_data(data: Dict[str, Any]) -> bool:
        """éªŒè¯ä»·æ ¼æ•°æ®"""
        required_fields = ['price', 'timestamp']
        return all(field in data for field in required_fields)
    
    @staticmethod
    def validate_signal_data(data: Dict[str, Any]) -> bool:
        """éªŒè¯ä¿¡å·æ•°æ®"""
        required_fields = ['signal', 'confidence', 'reason']
        return all(field in data for field in required_fields)
    
    @staticmethod
    def validate_position_data(data: Dict[str, Any]) -> bool:
        """éªŒè¯æŒä»“æ•°æ®"""
        required_fields = ['side', 'size', 'entry_price']
        return all(field in data for field in required_fields)

class JSONHelper:
    """JSONå·¥å…·ç±»"""
    
    @staticmethod
    def safe_parse(json_str: str) -> Optional[Dict[str, Any]]:
        """å®‰å…¨è§£æJSON"""
        try:
            return json.loads(json_str)
        except (json.JSONDecodeError, ValueError):
            return None
    
    @staticmethod
    def safe_stringify(obj: Any) -> str:
        """å®‰å…¨åºåˆ—åŒ–JSON"""
        try:
            return json.dumps(obj, ensure_ascii=False, default=str)
        except (TypeError, ValueError):
            return str(obj)
    
    @staticmethod
    def safe_json_serialize(obj: Any) -> str:
        """å®‰å…¨åºåˆ—åŒ–JSON"""
        try:
            return json.dumps(obj, ensure_ascii=False, indent=2, default=str)
        except Exception as e:
            log_warning(f"JSONåºåˆ—åŒ–å¤±è´¥: {e}")
            return str(obj)

# æ•´åˆæ—¥å¿—å’Œæ•°æ®ç®¡ç†åŠŸèƒ½
# LoggerConfigç±»å·²ç§»é™¤ï¼Œç»Ÿä¸€ä½¿ç”¨é¡¹ç›®çº§æ—¥å¿—é…ç½®

class TradeLogger:
    """äº¤æ˜“æ—¥å¿—ç®¡ç† - æ•´åˆtrade_logger.pyåŠŸèƒ½"""
    
    def __init__(self):
        from pathlib import Path
        self.trade_log_file = Path("logs") / "trades.json"
        self.trade_log_file.parent.mkdir(exist_ok=True)
    
    def log_ai_decision(self, decision_data):
        """è®°å½•AIå†³ç­–"""
        import json
        from datetime import datetime
        
        log_entry = {
            "type": "AI_DECISION",
            "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "signal": decision_data.get('signal', 'HOLD'),
            "confidence": decision_data.get('confidence', 'N/A'),
            "reason": decision_data.get('reason', ''),
            "price": decision_data.get('price', 0)
        }
        
        try:
            with open(self.trade_log_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
        except Exception as e:
            log_error(f"è®°å½•AIå†³ç­–å¤±è´¥: {e}")

class DataManager:
    """æ•°æ®ç®¡ç† - æ•´åˆæ•°æ®ç®¡ç†åŠŸèƒ½"""
    
    def __init__(self):
        from pathlib import Path
        self.data_dir = Path(__file__).parent / "data_json"
        self.data_dir.mkdir(exist_ok=True)
        
        self.data_file = self.data_dir / "trading_data.json"
        self.trades_file = self.data_dir / "trades_history.json"
        self.equity_file = self.data_dir / "equity_history.json"
    
    def save_trading_data(self, data):
        """ä¿å­˜äº¤æ˜“æ•°æ®"""
        try:
            with open(self.data_file, 'w', encoding='utf-8') as f:
                import json
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            log_error(f"ä¿å­˜äº¤æ˜“æ•°æ®å¤±è´¥: {e}")
    
    def load_trading_data(self):
        """åŠ è½½äº¤æ˜“æ•°æ®"""
        try:
            if self.data_file.exists():
                import json
                with open(self.data_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            log_error(f"åŠ è½½äº¤æ˜“æ•°æ®å¤±è´¥: {e}")
            return {}
    
    def save_market_data(self, data):
        """ä¿å­˜å¸‚åœºæ•°æ®"""
        self.save_trading_data(data)
    
    def get_data_summary(self):
        """è·å–æ•°æ®æ‘˜è¦"""
        try:
            summary = {}
            
            # äº¤æ˜“æ•°æ®æ‘˜è¦
            if self.data_file.exists():
                data = self.load_trading_data()
                summary['trading_data'] = {
                    'total_records': len(data) if isinstance(data, dict) else 0,
                    'last_update': data.get('timestamp', 'æœªçŸ¥') if isinstance(data, dict) else 'æœªçŸ¥'
                }
            else:
                summary['trading_data'] = {'total_records': 0, 'last_update': 'æ— æ•°æ®'}
            
            # å¸‚åœºæ•°æ®æ‘˜è¦
            summary['market_data'] = {'total_records': 0, 'last_update': 'æ— æ•°æ®'}
            
            return summary
            
        except Exception as e:
            log_error(f"è·å–æ•°æ®æ‘˜è¦å¤±è´¥: {e}")
            return {'trading_data': {'total_records': 0, 'last_update': 'é”™è¯¯'}, 
                   'market_data': {'total_records': 0, 'last_update': 'é”™è¯¯'}}
    
    def cleanup_old_data(self, days_to_keep=30):
        """æ¸…ç†æ—§æ•°æ®"""
        try:
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)
            # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„æ¸…ç†é€»è¾‘
            log_info(f"ğŸ“Š æ•°æ®æ¸…ç†å®Œæˆï¼Œä¿ç•™{days_to_keep}å¤©å†…æ•°æ®")
        except Exception as e:
            log_error(f"æ¸…ç†æ—§æ•°æ®å¤±è´¥: {e}")
    
    def save_ai_signal(self, signal_data):
        """ä¿å­˜AIä¿¡å·"""
        try:
            signals_file = self.data_dir / "ai_signals.json"
            existing_signals = []
            
            if signals_file.exists():
                with open(signals_file, 'r', encoding='utf-8') as f:
                    existing_signals = json.load(f)
            
            existing_signals.append(signal_data)
            
            # ä¿ç•™æœ€è¿‘100ä¸ªä¿¡å·
            if len(existing_signals) > 100:
                existing_signals = existing_signals[-100:]
            
            with open(signals_file, 'w', encoding='utf-8') as f:
                json.dump(existing_signals, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            log_error(f"ä¿å­˜AIä¿¡å·å¤±è´¥: {e}")
    
    def save_performance_metrics(self, metrics):
        """ä¿å­˜æ€§èƒ½æŒ‡æ ‡"""
        try:
            metrics_file = self.data_dir / "performance_metrics.json"
            existing_metrics = []
            
            if metrics_file.exists():
                with open(metrics_file, 'r', encoding='utf-8') as f:
                    existing_metrics = json.load(f)
            
            existing_metrics.append(metrics)
            
            # ä¿ç•™æœ€è¿‘1000ä¸ªæŒ‡æ ‡
            if len(existing_metrics) > 1000:
                existing_metrics = existing_metrics[-1000:]
            
            with open(metrics_file, 'w', encoding='utf-8') as f:
                json.dump(existing_metrics, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            log_error(f"ä¿å­˜æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")

class TimeHelper:
    """æ—¶é—´å·¥å…·ç±»"""
    
    @staticmethod
    def format_duration(seconds: float) -> str:
        """æ ¼å¼åŒ–æŒç»­æ—¶é—´"""
        return str(timedelta(seconds=int(seconds)))
    
    @staticmethod
    def is_market_hours() -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºäº¤æ˜“æ—¶é—´"""
        # åŠ å¯†è´§å¸24å°æ—¶äº¤æ˜“
        return True
    
    @staticmethod
    def get_time_until_next(interval_minutes: int = 15) -> float:
        """è·å–åˆ°ä¸‹ä¸ªå‘¨æœŸçš„æ—¶é—´
        
        æ”¯æŒ15åˆ†é’Ÿå¾ªç¯å‘¨æœŸï¼Œåœ¨æ¯ä¸ªæ•´ç‚¹çš„00ã€15ã€30ã€45åˆ†é’Ÿå¼€å§‹è¿è¡Œ
        """
        now = datetime.now()
        minutes = now.minute
        
        # è®¡ç®—ä¸‹ä¸€ä¸ª15åˆ†é’Ÿé—´éš”
        next_interval = ((minutes // interval_minutes) + 1) * interval_minutes
        
        if next_interval >= 60:
            next_interval = 0
            next_hour = now.hour + 1
        else:
            next_hour = now.hour
        
        # å¤„ç†å°æ—¶æº¢å‡º
        if next_hour >= 24:
            next_hour = 0
            next_day = now.day + 1
            # å¤„ç†æœˆä»½å¤©æ•°å˜åŒ–
            try:
                next_time = now.replace(day=next_day, hour=next_hour, minute=next_interval, second=0, microsecond=0)
            except ValueError:
                # å¦‚æœæ—¥æœŸæ— æ•ˆï¼ˆå¦‚2æœˆ30æ—¥ï¼‰ï¼Œåˆ™ä½¿ç”¨ä¸‹ä¸ªæœˆçš„ç¬¬ä¸€å¤©
                next_month = now.month + 1
                next_year = now.year
                if next_month > 12:
                    next_month = 1
                    next_year += 1
                next_time = datetime(next_year, next_month, 1, next_hour, next_interval, 0, 0)
        else:
            try:
                next_time = now.replace(hour=next_hour, minute=next_interval, second=0, microsecond=0)
            except ValueError:
                # å¤„ç†å¤ä»¤æ—¶ç­‰ç‰¹æ®Šæƒ…å†µ
                next_time = now + timedelta(hours=1)
                next_time = next_time.replace(minute=next_interval, second=0, microsecond=0)
        
        return max(0, (next_time - now).total_seconds())

class LoggerHelper:
    """æ—¥å¿—è¾…åŠ©ç±»"""
    
    @staticmethod
    def log_trade_event(event_type: str, data: Dict[str, Any]) -> None:
        """è®°å½•äº¤æ˜“äº‹ä»¶"""
        log_data = {
            'event_type': event_type,
            'timestamp': datetime.now().isoformat(),
            'data': data
        }
        
        # ä½¿ç”¨TradeLoggerè®°å½•äº‹ä»¶
        trade_logger_instance = TradeLogger()
        trade_logger_instance.log_ai_decision(log_data)
        log_info(f"ğŸ“Š äº¤æ˜“äº‹ä»¶: {event_type} - {data}")
    
    @staticmethod
    def log_error_event(error_type: str, error_data: Dict[str, Any]) -> None:
        """è®°å½•é”™è¯¯äº‹ä»¶"""
        error_info = {
            'error_type': error_type,
            'timestamp': datetime.now().isoformat(),
            'error_data': error_data
        }
        
        log_error(f"âŒ é”™è¯¯äº‹ä»¶: {error_type} - {error_data}")
        # ä½¿ç”¨TradeLoggerè®°å½•é”™è¯¯
        trade_logger_instance = TradeLogger()
        trade_logger_instance.log_ai_decision(error_info)

class ErrorClassifier:
    """é”™è¯¯åˆ†ç±»å™¨"""
    
    def __init__(self):
        self.classification_rules = {
            'network': [
                'ConnectionError', 'TimeoutError', 'NetworkError',
                'SSLError', 'ProxyError', 'DNSLookupError', 'ConnectionResetError'
            ],
            'api': [
                'APIError', 'RateLimitError', 'AuthenticationError',
                'PermissionError', 'InvalidRequestError', 'ExchangeError',
                'InsufficientFunds', 'InvalidOrder', 'OrderNotFound'
            ],
            'data': [
                'DataError', 'ValidationError', 'MissingDataError',
                'PriceError', 'TimestampError', 'FormatError', 'JSONDecodeError'
            ],
            'system': [
                'MemoryError', 'SystemError', 'ProcessError',
                'ResourceError', 'ThreadError', 'QueueError', 'OSError'
            ],
            'strategy': [
                'StrategyError', 'CalculationError', 'LogicError',
                'ConfigurationError', 'ParameterError'
            ]
        }
    
    def classify_error(self, error: Exception) -> str:
        """å¯¹é”™è¯¯è¿›è¡Œåˆ†ç±»"""
        error_name = type(error).__name__
        error_message = str(error).lower()
        
        for category, patterns in self.classification_rules.items():
            if any(pattern.lower() in error_name.lower() or 
                   pattern.lower() in error_message 
                   for pattern in patterns):
                return category
        
        return 'unknown'

class ErrorRecoveryManager:
    """å¼‚å¸¸æ¢å¤ç®¡ç†å™¨"""
    
    def __init__(self):
        # å»¶è¿Ÿå¯¼å…¥configï¼Œé¿å…å¾ªç¯å¯¼å…¥
        try:
            from config import config
            self.config = config.get('system', 'error_recovery') or {}
        except ImportError:
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
            self.config = {
                'network': {'max_retries': 3, 'retry_delay': 5, 'cooldown_duration': 60},
                'api': {'max_retries': 2, 'retry_delay': 3},
                'rate_limit': {'backoff_multiplier': 2, 'base_delay': 10},
                'system': {'memory_threshold': 0.8}
            }
        
        self.error_classifier = ErrorClassifier()
        self.recovery_strategies = {
            'network': self._handle_network_error,
            'api': self._handle_api_error,
            'data': self._handle_data_error,
            'system': self._handle_system_error,
            'strategy': self._handle_strategy_error,
            'unknown': self._handle_unknown_error
        }
        self.error_history = []
        self.recovery_stats = {'total_errors': 0, 'successful_recoveries': 0}
    
    def handle_error(self, error: Exception, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å…¥å£"""
        
        self.recovery_stats['total_errors'] += 1
        
        # 1. é”™è¯¯åˆ†ç±»
        error_category = self.error_classifier.classify_error(error)
        
        # 2. è®°å½•é”™è¯¯
        error_record = self._record_error(error, error_category, context)
        
        # 3. æ‰§è¡Œæ¢å¤ç­–ç•¥
        recovery_result = self._execute_recovery(error_category, error, context)
        
        # 4. æ›´æ–°ç»Ÿè®¡
        if recovery_result['success']:
            self.recovery_stats['successful_recoveries'] += 1
        
        # 5. å‘é€è­¦æŠ¥
        if recovery_result['severity'] in ['HIGH', 'CRITICAL']:
            self._send_alert(error_record, recovery_result)
        
        return recovery_result
    
    def _record_error(self, error: Exception, category: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """è®°å½•é”™è¯¯ä¿¡æ¯"""
        error_record = {
            'timestamp': datetime.now().isoformat(),
            'error_type': type(error).__name__,
            'error_message': str(error),
            'category': category,
            'context': context or {},
            'stack_trace': self._get_stack_trace(),
            'recovery_attempt': 0
        }
        
        self.error_history.append(error_record)
        
        # ä¿ç•™æœ€è¿‘100æ¡é”™è¯¯è®°å½•
        if len(self.error_history) > 100:
            self.error_history.pop(0)
        
        return error_record
    
    def _execute_recovery(self, category: str, error: Exception, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ¢å¤ç­–ç•¥"""
        
        recovery_handler = self.recovery_strategies.get(category, self._handle_unknown_error)
        
        try:
            return recovery_handler(error, context)
        except Exception as recovery_error:
            log_error(f"æ¢å¤ç­–ç•¥æ‰§è¡Œå¤±è´¥: {recovery_error}")
            return {
                'success': False,
                'action': 'FALLBACK_SHUTDOWN',
                'severity': 'CRITICAL',
                'message': f'æ¢å¤ç­–ç•¥å¤±è´¥: {recovery_error}',
                'next_action': 'SAFE_SHUTDOWN'
            }
    
    def _handle_network_error(self, error: Exception, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†ç½‘ç»œé”™è¯¯"""
        
        retry_config = self.config.get('network', {})
        max_retries = retry_config.get('max_retries', 3)
        retry_delay = retry_config.get('retry_delay', 5)
        
        retry_count = context.get('retry_count', 0)
        
        if retry_count < max_retries:
            log_info(f"ğŸ”„ ç½‘ç»œé”™è¯¯æ¢å¤ - é‡è¯• {retry_count + 1}/{max_retries}")
            time.sleep(retry_delay)
            return {
                'success': True,
                'action': 'RETRY',
                'severity': 'LOW',
                'message': f'ç½‘ç»œé”™è¯¯ï¼Œ{retry_delay}ç§’åé‡è¯•',
                'next_action': 'CONTINUE',
                'retry_count': retry_count + 1
            }
        else:
            return {
                'success': False,
                'action': 'NETWORK_BACKOFF',
                'severity': 'HIGH',
                'message': 'ç½‘ç»œé”™è¯¯é‡è¯•æ¬¡æ•°ç”¨å°½ï¼Œè¿›å…¥å†·å´æ¨¡å¼',
                'next_action': 'COOLDOWN',
                'cooldown_duration': retry_config.get('cooldown_duration', 60)
            }
    
    def _handle_api_error(self, error: Exception, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†APIé”™è¯¯"""
        
        error_message = str(error).lower()
        
        if 'rate limit' in error_message or '429' in error_message:
            return self._handle_rate_limit_error(context)
        elif 'authentication' in error_message or '401' in error_message:
            return self._handle_authentication_error(context)
        elif 'insufficient funds' in error_message:
            return self._handle_insufficient_funds_error(context)
        else:
            return self._handle_generic_api_error(error, context)
    
    def _handle_rate_limit_error(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†é™é¢‘é”™è¯¯"""
        
        rate_limit_config = self.config.get('rate_limit', {})
        backoff_multiplier = rate_limit_config.get('backoff_multiplier', 2)
        base_delay = rate_limit_config.get('base_delay', 10)
        
        retry_count = context.get('retry_count', 0)
        delay = base_delay * (backoff_multiplier ** retry_count)
        
        log_info(f"â±ï¸ é™é¢‘ä¿æŠ¤ - ç­‰å¾… {delay} ç§’")
        time.sleep(min(delay, 60))  # æœ€å¤§ç­‰å¾…60ç§’
        
        return {
            'success': True,
            'action': 'RATE_LIMIT_BACKOFF',
            'severity': 'MEDIUM',
            'message': f'é™é¢‘ä¿æŠ¤ï¼Œç­‰å¾…{delay}ç§’',
            'next_action': 'RETRY',
            'retry_count': retry_count + 1
        }
    
    def _handle_authentication_error(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†è®¤è¯é”™è¯¯"""
        
        log_error("ğŸ” APIè®¤è¯å¤±è´¥ - éœ€è¦æ£€æŸ¥APIå¯†é’¥é…ç½®")
        return {
            'success': False,
            'action': 'AUTH_FAILURE',
            'severity': 'CRITICAL',
            'message': 'APIè®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®',
            'next_action': 'STOP_TRADING'
        }
    
    def _handle_insufficient_funds_error(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†èµ„é‡‘ä¸è¶³é”™è¯¯"""
        
        log_warning("ğŸ’° èµ„é‡‘ä¸è¶³ - è°ƒæ•´äº¤æ˜“è§„æ¨¡")
        return {
            'success': True,
            'action': 'ADJUST_POSITION_SIZE',
            'severity': 'MEDIUM',
            'message': 'èµ„é‡‘ä¸è¶³ï¼Œè°ƒæ•´äº¤æ˜“è§„æ¨¡',
            'next_action': 'CONTINUE_WITH_REDUCED_SIZE',
            'reduction_factor': 0.5
        }
    
    def _handle_generic_api_error(self, error: Exception, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†é€šç”¨APIé”™è¯¯"""
        
        retry_config = self.config.get('api', {})
        max_retries = retry_config.get('max_retries', 2)
        retry_delay = retry_config.get('retry_delay', 3)
        
        retry_count = context.get('retry_count', 0)
        
        if retry_count < max_retries:
            log_info(f"ğŸ”„ APIé”™è¯¯æ¢å¤ - é‡è¯• {retry_count + 1}/{max_retries}")
            time.sleep(retry_delay)
            return {
                'success': True,
                'action': 'API_RETRY',
                'severity': 'LOW',
                'message': f'APIé”™è¯¯ï¼Œ{retry_delay}ç§’åé‡è¯•',
                'next_action': 'RETRY',
                'retry_count': retry_count + 1
            }
        else:
            return {
                'success': False,
                'action': 'API_FAILURE',
                'severity': 'HIGH',
                'message': 'APIé”™è¯¯é‡è¯•æ¬¡æ•°ç”¨å°½',
                'next_action': 'SWITCH_TO_BACKUP'
            }
    
    def _handle_data_error(self, error: Exception, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æ•°æ®é”™è¯¯"""
        
        log_info("ğŸ“Š æ•°æ®é”™è¯¯ - ä½¿ç”¨ç¼“å­˜æˆ–é»˜è®¤å€¼")
        return {
            'success': True,
            'action': 'USE_FALLBACK_DATA',
            'severity': 'LOW',
            'message': 'æ•°æ®é”™è¯¯ï¼Œä½¿ç”¨ç¼“å­˜æˆ–é»˜è®¤å€¼',
            'next_action': 'CONTINUE_WITH_FALLBACK'
        }
    
    def _handle_system_error(self, error: Exception, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†ç³»ç»Ÿé”™è¯¯"""
        
        system_config = self.config.get('system', {})
        memory_threshold = system_config.get('memory_threshold', 0.8)
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
        import psutil
        memory_usage = psutil.virtual_memory().percent / 100
        
        if memory_usage > memory_threshold:
            log_warning(f"ğŸ§  å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory_usage:.2%}")
            # æ¸…ç†ç¼“å­˜
            cache_manager.clear_cache()
            memory_manager.force_cleanup()
            
            return {
                'success': True,
                'action': 'MEMORY_CLEANUP',
                'severity': 'MEDIUM',
                'message': 'å†…å­˜æ¸…ç†å®Œæˆ',
                'next_action': 'CONTINUE'
            }
        
        return {
            'success': False,
            'action': 'SYSTEM_FAILURE',
            'severity': 'CRITICAL',
            'message': 'ç³»ç»Ÿé”™è¯¯ï¼Œæ— æ³•è‡ªåŠ¨æ¢å¤',
            'next_action': 'SAFE_SHUTDOWN'
        }
    
    def _handle_strategy_error(self, error: Exception, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†ç­–ç•¥é”™è¯¯"""
        
        log_info("ğŸ¯ ç­–ç•¥é”™è¯¯ - ä½¿ç”¨ä¿å®ˆç­–ç•¥")
        return {
            'success': True,
            'action': 'USE_CONSERVATIVE_STRATEGY',
            'severity': 'LOW',
            'message': 'ç­–ç•¥é”™è¯¯ï¼Œä½¿ç”¨ä¿å®ˆç­–ç•¥',
            'next_action': 'CONTINUE_WITH_CONSERVATIVE_MODE'
        }
    
    def _handle_unknown_error(self, error: Exception, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æœªçŸ¥é”™è¯¯"""
        
        log_error(f"â“ æœªçŸ¥é”™è¯¯: {error}")
        return {
            'success': False,
            'action': 'UNKNOWN_ERROR',
            'severity': 'HIGH',
            'message': f'æœªçŸ¥é”™è¯¯: {error}',
            'next_action': 'SAFE_SHUTDOWN'
        }
    
    def _get_stack_trace(self) -> str:
        """è·å–å †æ ˆè·Ÿè¸ª"""
        import traceback
        return traceback.format_exc()
    
    def _send_alert(self, error_record: Dict[str, Any], recovery_result: Dict[str, Any]):
        """å‘é€é”™è¯¯è­¦æŠ¥"""
        alert_message = f"""
        ğŸš¨ äº¤æ˜“ç³»ç»Ÿé”™è¯¯è­¦æŠ¥
        
        æ—¶é—´: {error_record['timestamp']}
        é”™è¯¯ç±»å‹: {error_record['error_type']}
        é”™è¯¯åˆ†ç±»: {error_record['category']}
        ä¸¥é‡ç¨‹åº¦: {recovery_result['severity']}
        æ¢å¤åŠ¨ä½œ: {recovery_result['action']}
        ä¸‹ä¸€æ­¥è¡ŒåŠ¨: {recovery_result['next_action']}
        
        é”™è¯¯è¯¦æƒ…: {error_record['error_message']}
        ä¸Šä¸‹æ–‡: {json.dumps(error_record['context'], indent=2)}
        """
        
        log_error(alert_message)
        # å®é™…åº”ç”¨ä¸­è¿™é‡Œä¼šå‘é€é‚®ä»¶ã€çŸ­ä¿¡ç­‰é€šçŸ¥
    
    def get_recovery_stats(self) -> Dict[str, Any]:
        """è·å–æ¢å¤ç»Ÿè®¡"""
        return {
            'total_errors': self.recovery_stats['total_errors'],
            'successful_recoveries': self.recovery_stats['successful_recoveries'],
            'recovery_rate': (
                self.recovery_stats['successful_recoveries'] / 
                max(self.recovery_stats['total_errors'], 1)
            ),
            'recent_errors': self.error_history[-10:],  # æœ€è¿‘10æ¡é”™è¯¯
            'error_distribution': self._get_error_distribution()
        }
    
    def _get_error_distribution(self) -> Dict[str, int]:
        """è·å–é”™è¯¯åˆ†å¸ƒç»Ÿè®¡"""
        distribution = {}
        for error in self.error_history:
            category = error['category']
            distribution[category] = distribution.get(category, 0) + 1
        return distribution

class StatePersistence:
    """çŠ¶æ€æŒä¹…åŒ–ç®¡ç†å™¨"""
    
    def __init__(self):
        # å»¶è¿Ÿå¯¼å…¥configï¼Œé¿å…å¾ªç¯å¯¼å…¥
        try:
            from config import config
            self.config = config.get('system', 'state_persistence') or {}
            self.state_dir = self.config.get('state_dir', './data/state')
            self.checkpoint_interval = self.config.get('checkpoint_interval', 300)  # 5åˆ†é’Ÿ
            self.max_checkpoints = self.config.get('max_checkpoints', 10)
        except ImportError:
            # ä½¿ç”¨é»˜è®¤é…ç½®
            self.state_dir = './data/state'
            self.checkpoint_interval = 300
            self.max_checkpoints = 10
        
        # ç¡®ä¿çŠ¶æ€ç›®å½•å­˜åœ¨
        os.makedirs(self.state_dir, exist_ok=True)
    
    def save_state(self, state_type: str, data: Dict[str, Any]) -> bool:
        """ä¿å­˜çŠ¶æ€"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{state_type}_{timestamp}.json"
            filepath = os.path.join(self.state_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            # æ¸…ç†æ—§çš„çŠ¶æ€æ–‡ä»¶
            self._cleanup_old_states(state_type)
            
            return True
            
        except Exception as e:
            log_error(f"ä¿å­˜çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def load_latest_state(self, state_type: str) -> Optional[Dict[str, Any]]:
        """åŠ è½½æœ€æ–°çŠ¶æ€"""
        try:
            pattern = f"{state_type}_*.json"
            files = glob.glob(os.path.join(self.state_dir, pattern))
            
            if not files:
                return None
            
            latest_file = max(files, key=os.path.getctime)
            
            with open(latest_file, 'r', encoding='utf-8') as f:
                return json.load(f)
                
        except Exception as e:
            log_error(f"åŠ è½½çŠ¶æ€å¤±è´¥: {e}")
            return None
    
    def _cleanup_old_states(self, state_type: str):
        """æ¸…ç†æ—§çš„çŠ¶æ€æ–‡ä»¶"""
        try:
            pattern = f"{state_type}_*.json"
            files = glob.glob(os.path.join(self.state_dir, pattern))
            
            # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œä¿ç•™æœ€æ–°çš„max_checkpointsä¸ª
            files.sort(key=os.path.getctime, reverse=True)
            
            for old_file in files[self.max_checkpoints:]:
                try:
                    os.remove(old_file)
                except Exception as e:
                    log_warning(f"åˆ é™¤æ—§çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
                    
        except Exception as e:
            log_error(f"æ¸…ç†çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")

class RecoveryEngine:
    """æ¢å¤å¼•æ“"""
    
    def __init__(self):
        # å»¶è¿Ÿå¯¼å…¥configï¼Œé¿å…å¾ªç¯å¯¼å…¥
        try:
            from config import config
            self.config = config.get('system', 'recovery') or {}
        except ImportError:
            # ä½¿ç”¨é»˜è®¤é…ç½®
            self.config = {
                'enabled': True,
                'max_retries': 3,
                'retry_delay': 1,
                'backoff_factor': 2.0
            }
        
        self.enabled = self.config.get('enabled', True)
        self.max_retries = self.config.get('max_retries', 3)
        self.retry_delay = self.config.get('retry_delay', 1)
        self.backoff_factor = self.config.get('backoff_factor', 2.0)
        self.state_persistence = StatePersistence()
        self.error_recovery = ErrorRecoveryManager()
        self.checkpoint_manager = CheckpointManager()
    
    def create_checkpoint(self, system_state: Dict[str, Any]) -> bool:
        """åˆ›å»ºç³»ç»Ÿæ£€æŸ¥ç‚¹"""
        return self.checkpoint_manager.create_checkpoint(system_state)
    
    def restore_from_checkpoint(self, checkpoint_id: str = None) -> Dict[str, Any]:
        """ä»æ£€æŸ¥ç‚¹æ¢å¤"""
        return self.checkpoint_manager.restore_checkpoint(checkpoint_id)
    
    def get_system_health(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿå¥åº·çŠ¶æ€"""
        return {
            'error_recovery_stats': self.error_recovery.get_recovery_stats(),
            'last_checkpoint': self.checkpoint_manager.get_last_checkpoint(),
            'system_uptime': self._calculate_uptime(),
            'recovery_status': 'healthy'
        }
    
    def _calculate_uptime(self) -> str:
        """è®¡ç®—ç³»ç»Ÿè¿è¡Œæ—¶é—´"""
        # ç®€åŒ–ç‰ˆè¿è¡Œæ—¶é—´è®¡ç®—
        return "ç³»ç»Ÿè¿è¡Œæ­£å¸¸"

class CheckpointManager:
    """æ£€æŸ¥ç‚¹ç®¡ç†å™¨"""
    
    def __init__(self):
        # å»¶è¿Ÿå¯¼å…¥configï¼Œé¿å…å¾ªç¯å¯¼å…¥
        try:
            from config import config
            self.config = config.get('system', 'checkpoint_manager') or {}
            self.checkpoint_dir = self.config.get('checkpoint_dir', './data/checkpoints')
            self.max_checkpoints = self.config.get('max_checkpoints', 5)
        except ImportError:
            # ä½¿ç”¨é»˜è®¤é…ç½®
            self.checkpoint_dir = './data/checkpoints'
            self.max_checkpoints = 5
        
        # ç¡®ä¿æ£€æŸ¥ç‚¹ç›®å½•å­˜åœ¨
        os.makedirs(self.checkpoint_dir, exist_ok=True)
    
    def create_checkpoint(self, system_state: Dict[str, Any]) -> bool:
        """åˆ›å»ºç³»ç»Ÿæ£€æŸ¥ç‚¹"""
        try:
            checkpoint = {
                'timestamp': datetime.now().isoformat(),
                'system_state': system_state,
                'version': '1.0.0',
                'checksum': self._calculate_checksum(system_state)
            }
            
            filename = f"checkpoint_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            filepath = os.path.join(self.checkpoint_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(checkpoint, f, indent=2, ensure_ascii=False)
            
            # æ¸…ç†æ—§çš„æ£€æŸ¥ç‚¹
            self._cleanup_old_checkpoints()
            
            log_info(f"âœ… æ£€æŸ¥ç‚¹åˆ›å»ºæˆåŠŸ: {filename}")
            return True
            
        except Exception as e:
            log_error(f"åˆ›å»ºæ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            return False
    
    def restore_checkpoint(self, checkpoint_id: str = None) -> Dict[str, Any]:
        """ä»æ£€æŸ¥ç‚¹æ¢å¤"""
        try:
            checkpoints = self._list_checkpoints()
            
            if not checkpoints:
                return {'success': False, 'message': 'æ— å¯ç”¨æ£€æŸ¥ç‚¹'}
            
            if checkpoint_id:
                target_checkpoint = next((cp for cp in checkpoints if cp['id'] == checkpoint_id), None)
            else:
                target_checkpoint = checkpoints[0]  # æœ€æ–°çš„æ£€æŸ¥ç‚¹
            
            if not target_checkpoint:
                return {'success': False, 'message': 'æŒ‡å®šçš„æ£€æŸ¥ç‚¹ä¸å­˜åœ¨'}
            
            # éªŒè¯æ£€æŸ¥ç‚¹å®Œæ•´æ€§
            if not self._validate_checkpoint(target_checkpoint):
                return {'success': False, 'message': 'æ£€æŸ¥ç‚¹éªŒè¯å¤±è´¥'}
            
            return {
                'success': True,
                'checkpoint': target_checkpoint,
                'message': 'æ£€æŸ¥ç‚¹æ¢å¤æˆåŠŸ'
            }
            
        except Exception as e:
            log_error(f"æ¢å¤æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            return {'success': False, 'message': str(e)}
    
    def _list_checkpoints(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰æ£€æŸ¥ç‚¹"""
        try:
            files = glob.glob(os.path.join(self.checkpoint_dir, "checkpoint_*.json"))
            checkpoints = []
            
            for file in sorted(files, key=os.path.getctime, reverse=True):
                try:
                    with open(file, 'r', encoding='utf-8') as f:
                        checkpoint = json.load(f)
                        checkpoint['id'] = os.path.basename(file)
                        checkpoint['filepath'] = file
                        checkpoints.append(checkpoint)
                except Exception as e:
                    log_warning(f"åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            
            return checkpoints
            
        except Exception as e:
            log_error(f"åˆ—å‡ºæ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            return []
    
    def _validate_checkpoint(self, checkpoint: Dict[str, Any]) -> bool:
        """éªŒè¯æ£€æŸ¥ç‚¹å®Œæ•´æ€§"""
        try:
            expected_checksum = checkpoint.get('checksum')
            actual_checksum = self._calculate_checksum(checkpoint.get('system_state', {}))
            
            return expected_checksum == actual_checksum
            
        except Exception as e:
            log_error(f"éªŒè¯æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            return False
    
    def _calculate_checksum(self, data: Dict[str, Any]) -> str:
        """è®¡ç®—æ•°æ®æ ¡éªŒå’Œ"""
        import hashlib
        data_str = json.dumps(data, sort_keys=True)
        return hashlib.md5(data_str.encode()).hexdigest()
    
    def _cleanup_old_checkpoints(self):
        """æ¸…ç†æ—§çš„æ£€æŸ¥ç‚¹"""
        try:
            checkpoints = self._list_checkpoints()
            
            for old_checkpoint in checkpoints[self.max_checkpoints:]:
                try:
                    os.remove(old_checkpoint['filepath'])
                    log_info(f"ğŸ—‘ï¸ åˆ é™¤æ—§æ£€æŸ¥ç‚¹: {old_checkpoint['id']}")
                except Exception as e:
                    log_warning(f"åˆ é™¤æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
                    
        except Exception as e:
            log_error(f"æ¸…ç†æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
    
    def get_last_checkpoint(self) -> Optional[Dict[str, Any]]:
        """è·å–æœ€æ–°çš„æ£€æŸ¥ç‚¹"""
        checkpoints = self._list_checkpoints()
        return checkpoints[0] if checkpoints else None

class EnhancedSystemMonitor:
    """å¢å¼ºç³»ç»Ÿç›‘æ§å™¨"""
    
    def __init__(self):
        self.metrics = {
            'start_time': time.time(),
            'api_calls': 0,
            'trades_executed': 0,
            'errors_count': 0,
            'warnings_count': 0,
            'memory_usage': [],
            'cpu_usage': [],
            'network_latency': [],
            'performance_metrics': {}
        }
        self.lock = threading.Lock()
        self.monitoring_enabled = True
        
    def start_monitoring(self):
        """å¯åŠ¨ç›‘æ§"""
        self.monitoring_enabled = True
        self._start_background_monitoring()
        log_info("ğŸš€ ç³»ç»Ÿç›‘æ§å·²å¯åŠ¨")
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring_enabled = False
        log_info("ğŸ›‘ ç³»ç»Ÿç›‘æ§å·²åœæ­¢")
    
    def increment_counter(self, counter_name: str, value: int = 1):
        """å¢åŠ è®¡æ•°å™¨"""
        with self.lock:
            if counter_name in self.metrics:
                self.metrics[counter_name] += value
            else:
                self.metrics[counter_name] = value
    
    def record_metric(self, metric_name: str, value: Any):
        """è®°å½•æŒ‡æ ‡"""
        with self.lock:
            self.metrics[metric_name] = value
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        with self.lock:
            uptime = time.time() - self.metrics['start_time']
            
            return {
                'uptime': self._format_uptime(uptime),
                'uptime_seconds': uptime,
                'api_calls': self.metrics['api_calls'],
                'trades_executed': self.metrics['trades_executed'],
                'errors_count': self.metrics['errors_count'],
                'warnings_count': self.metrics['warnings_count'],
                'requests_per_minute': self.metrics['api_calls'] / max(uptime / 60, 1),
                'trades_per_hour': self.metrics['trades_executed'] / max(uptime / 3600, 1),
                'error_rate': self.metrics['errors_count'] / max(self.metrics['api_calls'], 1),
                'system_health': self._calculate_health_score(),
                'timestamp': datetime.now().isoformat()
            }
    
    def _format_uptime(self, seconds: float) -> str:
        """æ ¼å¼åŒ–è¿è¡Œæ—¶é—´"""
        days = int(seconds // 86400)
        hours = int((seconds % 86400) // 3600)
        minutes = int((seconds % 3600) // 60)
        
        if days > 0:
            return f"{days}å¤©{hours}å°æ—¶{minutes}åˆ†é’Ÿ"
        elif hours > 0:
            return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"
        else:
            return f"{minutes}åˆ†é’Ÿ"
    
    def _calculate_health_score(self) -> float:
        """è®¡ç®—ç³»ç»Ÿå¥åº·åˆ†æ•°"""
        if self.metrics['api_calls'] == 0:
            return 100.0
        
        error_rate = self.metrics['errors_count'] / self.metrics['api_calls']
        
        if error_rate < 0.01:
            return 100.0
        elif error_rate < 0.05:
            return 90.0
        elif error_rate < 0.1:
            return 75.0
        elif error_rate < 0.2:
            return 50.0
        else:
            return 25.0
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        return {
            'memory_usage': self._get_memory_usage(),
            'cpu_usage': self._get_cpu_usage(),
            'disk_usage': self._get_disk_usage(),
            'network_stats': self._get_network_stats(),
            'process_stats': self._get_process_stats()
        }
    
    def _get_memory_usage(self) -> Dict[str, float]:
        """è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        try:
            import psutil
            memory = psutil.virtual_memory()
            return {
                'total_gb': memory.total / (1024**3),
                'used_gb': memory.used / (1024**3),
                'available_gb': memory.available / (1024**3),
                'percent': memory.percent
            }
        except ImportError:
            return {'total_gb': 0, 'used_gb': 0, 'available_gb': 0, 'percent': 0}
    
    def _get_cpu_usage(self) -> Dict[str, float]:
        """è·å–CPUä½¿ç”¨æƒ…å†µ"""
        try:
            import psutil
            return {
                'cpu_percent': psutil.cpu_percent(interval=1),
                'cpu_count': psutil.cpu_count(),
                'load_average': psutil.getloadavg()[0] if hasattr(psutil, 'getloadavg') else 0
            }
        except ImportError:
            return {'cpu_percent': 0, 'cpu_count': 1, 'load_average': 0}
    
    def _get_disk_usage(self) -> Dict[str, float]:
        """è·å–ç£ç›˜ä½¿ç”¨æƒ…å†µ"""
        try:
            import psutil
            disk = psutil.disk_usage('/')
            return {
                'total_gb': disk.total / (1024**3),
                'used_gb': disk.used / (1024**3),
                'free_gb': disk.free / (1024**3),
                'percent': disk.percent
            }
        except ImportError:
            return {'total_gb': 0, 'used_gb': 0, 'free_gb': 0, 'percent': 0}
    
    def _get_network_stats(self) -> Dict[str, int]:
        """è·å–ç½‘ç»œç»Ÿè®¡"""
        try:
            import psutil
            net_io = psutil.net_io_counters()
            return {
                'bytes_sent': net_io.bytes_sent,
                'bytes_recv': net_io.bytes_recv,
                'packets_sent': net_io.packets_sent,
                'packets_recv': net_io.packets_recv
            }
        except ImportError:
            return {'bytes_sent': 0, 'bytes_recv': 0, 'packets_sent': 0, 'packets_recv': 0}
    
    def _get_process_stats(self) -> Dict[str, int]:
        """è·å–è¿›ç¨‹ç»Ÿè®¡"""
        try:
            import psutil
            process = psutil.Process()
            return {
                'pid': process.pid,
                'memory_mb': process.memory_info().rss / (1024**2),
                'cpu_percent': process.cpu_percent(),
                'threads': process.num_threads()
            }
        except ImportError:
            return {'pid': 0, 'memory_mb': 0, 'cpu_percent': 0, 'threads': 0}
    
    def _start_background_monitoring(self):
        """å¯åŠ¨åå°ç›‘æ§"""
        def monitor_worker():
            while self.monitoring_enabled:
                try:
                    # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
                    performance = self.get_performance_metrics()
                    
                    # è®°å½•å†…å­˜å’ŒCPUä½¿ç”¨
                    if 'memory_usage' in performance:
                        self.metrics['memory_usage'].append(performance['memory_usage'])
                        if len(self.metrics['memory_usage']) > 100:
                            self.metrics['memory_usage'].pop(0)
                    
                    if 'cpu_usage' in performance:
                        self.metrics['cpu_usage'].append(performance['cpu_usage'])
                        if len(self.metrics['cpu_usage']) > 100:
                            self.metrics['cpu_usage'].pop(0)
                    
                    # æ¯30ç§’æ”¶é›†ä¸€æ¬¡
                    time.sleep(30)
                    
                except Exception as e:
                    log_error(f"åå°ç›‘æ§å¼‚å¸¸: {e}")
                    time.sleep(60)
        
        # å¯åŠ¨åå°çº¿ç¨‹
        monitor_thread = threading.Thread(target=monitor_worker, daemon=True)
        monitor_thread.start()
    
    def generate_system_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç³»ç»ŸæŠ¥å‘Š"""
        return {
            'system_status': self.get_system_status(),
            'performance_metrics': self.get_performance_metrics(),
            'error_summary': {
                'total_errors': self.metrics['errors_count'],
                'total_warnings': self.metrics['warnings_count'],
                'error_categories': self._get_error_categories()
            },
            'recommendations': self._generate_recommendations()
        }
    
    def _get_error_categories(self) -> Dict[str, int]:
        """è·å–é”™è¯¯åˆ†ç±»ç»Ÿè®¡"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥ä»é”™è¯¯æ—¥å¿—ä¸­åˆ†æ
        return {
            'network': 0,
            'api': 0,
            'data': 0,
            'system': 0,
            'strategy': 0
        }
    
    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆç³»ç»Ÿå»ºè®®"""
        recommendations = []
        
        # åŸºäºå¥åº·åˆ†æ•°ç”Ÿæˆå»ºè®®
        health_score = self._calculate_health_score()
        
        if health_score < 50:
            recommendations.append("ç³»ç»Ÿå¥åº·åˆ†æ•°è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥é”™è¯¯æ—¥å¿—")
        
        if self.metrics['errors_count'] > 10:
            recommendations.append("é”™è¯¯æ•°é‡è¾ƒå¤šï¼Œå»ºè®®é‡å¯ç³»ç»Ÿæˆ–æ£€æŸ¥é…ç½®")
        
        if len(self.metrics['memory_usage']) > 0:
            last_memory = self.metrics['memory_usage'][-1]
            if last_memory.get('percent', 0) > 80:
                recommendations.append("å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®é‡å¯ç³»ç»Ÿ")
        
        if not recommendations:
            recommendations.append("ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œç»§ç»­ä¿æŒç›‘æ§")
        
        return recommendations

# å…¨å±€å·¥å…·å®ä¾‹
cache_manager = CacheManager()
memory_manager = MemoryManager()
system_monitor = SystemMonitor()
enhanced_system_monitor = EnhancedSystemMonitor()
data_validator = DataValidator()
json_helper = JSONHelper()
time_helper = TimeHelper()
logger_helper = LoggerHelper()
error_recovery = ErrorRecoveryManager()
recovery_engine = RecoveryEngine()

def load_trading_data_from_file(file_path: str = None) -> Dict[str, Any]:
    """ä»æ–‡ä»¶åŠ è½½äº¤æ˜“æ•°æ®ï¼ˆä¾›streamlitä½¿ç”¨ï¼‰"""
    try:
        from pathlib import Path
        import json
        
        if file_path is None:
            data_dir = Path(__file__).parent / "data_json"
            file_path = data_dir / "trading_data.json"
        
        if Path(file_path).exists():
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return {
                "status": "stopped",
                "last_update": "N/A",
                "account": {"balance": 0, "equity": 0, "leverage": 0},
                "btc": {"price": 0, "change": 0, "timeframe": "1h", "mode": "å…¨ä»“-å•å‘"},
                "position": None,
                "performance": {"total_pnl": 0, "win_rate": 0, "total_trades": 0},
                "ai_signal": {
                    "signal": "HOLD",
                    "confidence": "N/A",
                    "reason": "ç­‰å¾…äº¤æ˜“ç¨‹åºå¯åŠ¨...",
                    "stop_loss": 0,
                    "take_profit": 0,
                    "timestamp": "N/A"
                },
                "file_not_found": True
            }
    except Exception as e:
        log_error(f"åŠ è½½äº¤æ˜“æ•°æ®å¤±è´¥: {e}")
        return {}

def load_trades_history_from_file(file_path: str = None) -> List[Dict[str, Any]]:
    """ä»æ–‡ä»¶åŠ è½½äº¤æ˜“å†å²ï¼ˆä¾›streamlitä½¿ç”¨ï¼‰"""
    try:
        from pathlib import Path
        import json
        
        if file_path is None:
            data_dir = Path(__file__).parent / "data_json"
            file_path = data_dir / "trades_history.json"
        
        if Path(file_path).exists():
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return []
    except Exception as e:
        log_error(f"åŠ è½½äº¤æ˜“å†å²å¤±è´¥: {e}")
        return []

def load_equity_history_from_file(file_path: str = None) -> List[Dict[str, Any]]:
    """ä»æ–‡ä»¶åŠ è½½æƒç›Šå†å²ï¼ˆä¾›streamlitä½¿ç”¨ï¼‰"""
    try:
        from pathlib import Path
        import json
        
        if file_path is None:
            data_dir = Path(__file__).parent / "data_json"
            file_path = data_dir / "equity_history.json"
        
        if Path(file_path).exists():
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return []
    except Exception as e:
        log_error(f"åŠ è½½æƒç›Šå†å²å¤±è´¥: {e}")
        return []

def save_trade_record(trade_record: Dict[str, Any]) -> bool:
    """ä¿å­˜äº¤æ˜“è®°å½•åˆ°æ–‡ä»¶"""
    try:
        from pathlib import Path
        import json
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        data_dir = Path(__file__).parent / "data_json"
        data_dir.mkdir(exist_ok=True)
        
        # äº¤æ˜“è®°å½•æ–‡ä»¶
        trades_file = data_dir / "trades_history.json"
        
        # åŠ è½½ç°æœ‰è®°å½•
        existing_records = []
        if trades_file.exists():
            try:
                with open(trades_file, 'r', encoding='utf-8') as f:
                    existing_records = json.load(f)
            except (json.JSONDecodeError, IOError):
                existing_records = []
        
        # ç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
        if not isinstance(existing_records, list):
            existing_records = []
        
        # æ·»åŠ æ–°è®°å½•
        existing_records.append(trade_record)
        
        # ä¿å­˜æ›´æ–°åçš„è®°å½•
        with open(trades_file, 'w', encoding='utf-8') as f:
            json.dump(existing_records, f, ensure_ascii=False, indent=2)
        
        return True
        
    except Exception as e:
        log_error(f"ä¿å­˜äº¤æ˜“è®°å½•å¤±è´¥: {e}")
        return False
state_persistence = StatePersistence()
recovery_engine = RecoveryEngine()
checkpoint_manager = CheckpointManager()